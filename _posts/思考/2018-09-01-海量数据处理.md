---
layout: post
title:  面试中的海量数据处理问题
date:   2018-09-01 19:15:10
categories:  思考
tags: 面经
keywords: interview
description: 
---

## 给你1亿个URL，如何快速查找出指定的URL（创建自定义哈希索引）

哈希索引的应用，可以对URL进行MD5操作（这个操作就相当于为每个URL生成一个hashcode），然后再使用hash就能快速查找到指定URL。（避免冲突问题，最好在WHERE后面加入哈希值比较和对应列值比较）

## 从两个文件(各含50亿个url)中找出共同的url
分别扫描A，B两个文件，根据hash(url)%k(k为正整数，比如k = 1000，那么每个小文件只占用300M，内存完全可以放得下)将url划分到不同的k个文件中，比如a0，a1,....a999;b0，b1，...b999；这样处理后相同的url肯定在对应的小文件中（a0 vs b0,a1 vs b1,...a999 vs b999）因为相同的url%1000的值肯定相同，不对应的小文件不可能有相同的url；然后我们只要求出1000对小文件中相同的url即可。

比如对于a0 vs b0，我们可以遍历a0，将其中的url存放到hash_map中，然后遍历b0，如果b0中的某个url在hash_map中，则说明此url在a和b中同时存在，保存下来即可。

## 找到100亿个URL中重复的URL？

同样也是用hash去处理，分别存到1000个小文件中，重复的url肯定会分到同一个文件中去，接下来就是找重复的就是了。

## 给你1亿个URL，找出出现次数最多的10个URL

方法1：


* 1.按照IP地址的Hash(IP)24值，把海量IP日志分别存储到1024个小文件中。
* 2.对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；
* 3.可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP；
 
 
 
方法2：Top K法


借助堆结构，我们可以在log量级的时间内查找和调整；

可以维护一个K(该题目中是10)大小的小根堆，然后遍历1亿个URL，分别和根元素进行对比，如果比根元素大就入堆，删掉根节点，重新调整小根堆的结构。


 
